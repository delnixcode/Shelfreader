# üîç **OCR Code Explanation - ShelfReader P1**
## Comprendre et recr√©er le syst√®me OCR de d√©tection de livres

*Ce document explique en d√©tail le code OCR de ShelfReader P1, vous permettant de comprendre chaque concept et de recr√©er le syst√®me de z√©ro.*

---

## üìã **Table des mati√®res**
1. [Architecture g√©n√©rale](#architecture-g√©n√©rale)
2. [Concepts OCR fondamentaux](#concepts-ocr-fondamentaux)
3. [Classe BookOCR - Initialisation](#classe-bookocr---initialisation)
4. [Pr√©traitement d'image](#pr√©traitement-dimage)
5. [D√©tection de texte avec EasyOCR](#d√©tection-de-texte-avec-easyocr)
6. [D√©tection de texte avec Tesseract](#d√©tection-de-texte-avec-tesseract)
7. [Extraction des bo√Ætes de texte](#extraction-des-bo√Ætes-de-texte)
8. [Regroupement par livres](#regroupement-par-livres)
9. [Script de d√©tection principal](#script-de-d√©tection-principal)
10. [Interactions entre m√©thodes](#interactions-entre-m√©thodes)
11. [Interactions entre fichiers](#interactions-entre-fichiers)
12. [Flux d'ex√©cution d√©taill√©](#flux-dex√©cution-d√©taill√©)
13. [Comment recr√©er le syst√®me](#comment-recr√©er-le-syst√®me)

---

## üèóÔ∏è **Architecture g√©n√©rale**

Le syst√®me OCR de ShelfReader P1 est compos√© de **deux fichiers principaux** :

### `src/ocr_processor.py`
- **Classe principale** : `BookOCR`
- **Responsabilit√©s** :
  - Initialisation des moteurs OCR (EasyOCR/Tesseract)
  - Pr√©traitement des images
  - D√©tection de texte
  - Regroupement des textes par livre
  - Extraction des titres

### `scripts/ocr_detect.py`
- **Script utilitaire** : Interface en ligne de commande
- **Responsabilit√©s** :
  - Parsing des arguments
  - Configuration du syst√®me
  - Affichage des r√©sultats
  - Gestion des erreurs

### Flux de donn√©es :
```
Image ‚Üí Pr√©traitement ‚Üí D√©tection OCR ‚Üí Bo√Ætes de texte ‚Üí Regroupement ‚Üí Livres d√©tect√©s
```

---

## üéØ **Concepts OCR fondamentaux**

### Qu'est-ce que l'OCR ?
L'**OCR (Optical Character Recognition)** est la technologie qui permet de **convertir des images de texte en texte num√©rique**.

### D√©fis sp√©cifiques aux tranches de livres :
1. **Texte vertical** : Les titres sont √©crits verticalement sur les tranches
2. **Petite taille** : Texte souvent petit et fin
3. **Contraste variable** : Qualit√© d'impression in√©gale
4. **D√©formation** : Courbure des tranches de livres

### Moteurs OCR utilis√©s :

#### EasyOCR
- **Avantages** : D√©tection automatique des rotations, tr√®s pr√©cis
- **Inconv√©nients** : Plus lent, n√©cessite PyTorch
- **Usage** : Texte complexe, rotations multiples

#### Tesseract
- **Avantages** : Rapide, l√©ger, bon pour texte horizontal
- **Inconv√©nients** : Moins bon avec les rotations
- **Usage** : Texte simple, performance importante

---

## üîß **Classe BookOCR - Initialisation**

```python
class BookOCR:
    def __init__(self, languages, confidence_threshold, use_gpu=False, use_tesseract=False):
        self.use_tesseract = use_tesseract
        self.confidence_threshold = confidence_threshold

        if use_tesseract:
            # Configuration Tesseract
            self.tesseract_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ...'
            print(f"üîç OCR initialis√© - Tesseract, Seuil: {confidence_threshold}")
        else:
            # Initialisation EasyOCR
            self.reader = easyocr.Reader(languages, gpu=use_gpu)
            device = "GPU" if use_gpu else "CPU"
            print(f"üîç OCR initialis√© - EasyOCR, Langues: {languages}, Seuil: {confidence_threshold}, Device: {device}")
```

### Param√®tres d'initialisation :
- **`languages`** : Liste des langues (ex: `['en']` pour anglais)
- **`confidence_threshold`** : Seuil de confiance (0.0-1.0) pour filtrer les d√©tections
- **`use_gpu`** : Acc√©l√©rer avec GPU (n√©cessite CUDA)
- **`use_tesseract`** : Choisir Tesseract au lieu d'EasyOCR

### Configuration Tesseract :
```python
self.tesseract_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ...'
```
- `--oem 3` : Mode moteur par d√©faut
- `--psm 6` : Assume un bloc uniforme de texte
- `tessedit_char_whitelist` : Limite aux caract√®res alphanum√©riques

---

## üñºÔ∏è **Pr√©traitement d'image**

Le pr√©traitement am√©liore drastiquement la qualit√© de d√©tection OCR :

```python
def _preprocess_image(self, image):
    # 1. Conversion en niveaux de gris
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # 2. Am√©lioration du contraste (CLAHE)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(6,6))
    enhanced = clahe.apply(gray)

    # 3. R√©duction du bruit
    denoised = cv2.bilateralFilter(enhanced, 9, 75, 75)

    # 4. Am√©lioration de la nettet√©
    gaussian = cv2.GaussianBlur(denoised, (0, 0), 1.0)
    sharpened = cv2.addWeighted(denoised, 1.5, gaussian, -0.5, 0)

    # 5. Binarisation adaptative
    binary = cv2.adaptiveThreshold(sharpened, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 7, 3)

    # 6. Dilatation l√©g√®re
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))
    dilated = cv2.dilate(binary, kernel, iterations=1)

    return cv2.cvtColor(dilated, cv2.COLOR_GRAY2BGR)
```

### √âtapes du pr√©traitement :

#### 1. **Conversion en niveaux de gris**
```python
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
```
**Pourquoi ?** L'OCR fonctionne mieux sur des images en noir et blanc.

#### 2. **CLAHE (Contrast Limited Adaptive Histogram Equalization)**
```python
clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(6,6))
enhanced = clahe.apply(gray)
```
**Pourquoi ?** Am√©liore le contraste localement sans amplifier le bruit.

#### 3. **Filtre bilat√©ral**
```python
denoised = cv2.bilateralFilter(enhanced, 9, 75, 75)
```
**Pourquoi ?** R√©duit le bruit tout en pr√©servant les bords des caract√®res.

#### 4. **Unsharp masking**
```python
gaussian = cv2.GaussianBlur(denoised, (0, 0), 1.0)
sharpened = cv2.addWeighted(denoised, 1.5, gaussian, -0.5, 0)
```
**Pourquoi ?** Augmente la nettet√© des caract√®res.

#### 5. **Binarisation adaptative**
```python
binary = cv2.adaptiveThreshold(sharpened, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 7, 3)
```
**Pourquoi ?** Convertit en noir/blanc en s'adaptant aux variations d'√©clairage.

#### 6. **Dilatation**
```python
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))
dilated = cv2.dilate(binary, kernel, iterations=1)
```
**Pourquoi ?** Connecte les parties des caract√®res qui ont √©t√© s√©par√©es.

---

## üîç **D√©tection de texte avec EasyOCR**

EasyOCR est le moteur OCR principal :

```python
def get_text_and_confidence(self, pil_image, preprocess=True):
    # Conversion PIL ‚Üí NumPy ‚Üí BGR
    image_array = np.array(pil_image)
    bgr_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)

    # Pr√©traitement si demand√©
    if preprocess:
        bgr_image = self._preprocess_image(bgr_image)

    # D√©tection OCR avec param√®tres optimis√©s
    results = self.reader.readtext(
        bgr_image,
        rotation_info=[0, 90, 180, 270],  # D√©tecte toutes les orientations
        width_ths=0.3,      # Tol√©rance largeur
        height_ths=0.3,     # Tol√©rance hauteur
        contrast_ths=0.05,  # Seuil contraste tr√®s bas
        adjust_contrast=0.7, # Ajustement contraste
        text_threshold=0.5,  # Seuil d√©tection texte
        link_threshold=0.3   # Seuil liaison caract√®res
    )

    # Filtrage par confiance et longueur
    filtered_results = [
        r for r in results
        if r[2] >= self.confidence_threshold and len(r[1].strip()) >= 2
    ]

    return ' '.join([r[1] for r in filtered_results]), np.mean([r[2] for r in filtered_results])
```

### Param√®tres EasyOCR importants :

- **`rotation_info`** : D√©tecte le texte dans toutes les orientations
- **`width_ths/height_ths`** : Tol√©rance aux variations de taille
- **`contrast_ths`** : Sensibilit√© au contraste (tr√®s bas pour texte fin)
- **`text_threshold`** : Seuil de confiance pour consid√©rer du texte

### Format des r√©sultats EasyOCR :
```python
[
    [[[x1,y1], [x2,y2], [x3,y3], [x4,y4]], "texte d√©tect√©", confiance],
    ...
]
```

---

## üìù **D√©tection de texte avec Tesseract**

Tesseract est utilis√© comme alternative :

```python
def _tesseract_detect(self, pil_image):
    # Conversion et pr√©traitement
    image_array = np.array(pil_image)
    gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)

    # D√©tection avec Tesseract
    data = pytesseract.image_to_data(enhanced, config=self.tesseract_config, output_type=pytesseract.Output.DICT)

    results = []
    for i in range(len(data['text'])):
        text = data['text'][i].strip()
        confidence = int(data['conf'][i]) / 100.0

        if confidence > 0.1 and len(text) >= 2:
            x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]
            bbox = [[x, y], [x+w, y], [x+w, y+h], [x, y+h]]
            results.append([bbox, text, confidence])

    return results
```

### Avantages de Tesseract :
- Plus rapide que EasyOCR
- Meilleur pour le texte horizontal long
- Moins de d√©pendances

### Inconv√©nients :
- Moins performant sur les rotations
- Pr√©configuration n√©cessaire pour le texte vertical

---

## üì¶ **Extraction des bo√Ætes de texte**

La m√©thode `get_boxes()` extrait les coordonn√©es de chaque texte d√©tect√© :

```python
def get_boxes(self, pil_image, preprocess=False, vertical_only=False):
    # D√©tection OCR (EasyOCR ou Tesseract)
    results = self._tesseract_detect(pil_image) if self.use_tesseract else self.reader.readtext(...)

    boxes = []
    for bbox, text, confidence in results:
        # Filtrage de qualit√©
        if confidence < 0.1 or len(text.strip()) < 1:
            continue

        # Calcul des dimensions
        x = min([p[0] for p in bbox])
        y = min([p[1] for p in bbox])
        width = max([p[0] for p in bbox]) - x
        height = max([p[1] for p in bbox]) - y
        font_size = height  # Approximation

        # D√©tection texte vertical
        is_vertical = self._is_vertical_text(bbox)

        if vertical_only and not is_vertical:
            continue

        boxes.append({
            "text": text,
            "x": x, "y": y,
            "width": width, "height": height,
            "font_size": font_size,
            "is_vertical": is_vertical
        })

    return boxes
```

### D√©tection du texte vertical :
```python
def _is_vertical_text(self, bbox):
    width = max([p[0] for p in bbox]) - min([p[0] for p in bbox])
    height = max([p[1] for p in bbox]) - min([p[1] for p in bbox])
    return height > width * 1.5  # Ratio hauteur/largeur > 1.5
```

---

## üìö **Regroupement par livres**

L'algorithme principal regroupe les textes par livre :

```python
def group_by_books(self, boxes, vertical_threshold=50):
    # 1. Filtrer les textes verticaux avec grandes polices
    vertical_boxes = [b for b in boxes if b.get('is_vertical', False)]
    if not vertical_boxes:
        return []

    # 2. Calculer la m√©diane de la taille de police
    font_sizes = [b['font_size'] for b in vertical_boxes]
    median_font_size = sorted(font_sizes)[len(font_sizes) // 2]

    # 3. Garder seulement les grandes polices
    large_text_boxes = [b for b in vertical_boxes if b['font_size'] >= median_font_size * 0.8]

    # 4. Trier par position X (gauche √† droite)
    sorted_boxes = sorted(large_text_boxes, key=lambda b: b['x'])

    # 5. Regrouper par colonnes (m√™me livre)
    books = []
    current_book = [sorted_boxes[0]]
    current_x = sorted_boxes[0]['x']

    for box in sorted_boxes[1:]:
        if abs(box['x'] - current_x) <= vertical_threshold:
            current_book.append(box)  # M√™me livre
        else:
            books.append(current_book)  # Nouveau livre
            current_book = [box]
            current_x = box['x']

    if current_book:
        books.append(current_book)

    # 6. Extraire les titres
    formatted_books = []
    for book_texts in books:
        title = self._extract_book_title(book_texts)
        formatted_books.append({
            'title': title,
            'x': book_texts[0]['x'],
            'all_texts': [b['text'] for b in book_texts],
            'text_count': len(book_texts)
        })

    return formatted_books
```

### Logique de regroupement :

1. **Filtrage vertical** : Seuls les textes verticaux (sur les tranches)
2. **Filtrage par taille** : Les grands textes (titres) vs petits textes (auteurs)
3. **Tri horizontal** : De gauche √† droite dans l'image
4. **Regroupement spatial** : Textes proches horizontalement = m√™me livre
5. **Reconstruction** : Combiner tous les textes d'un livre en titre

### Extraction du titre :
```python
def _extract_book_title(self, book_texts):
    # Trier verticalement (haut vers bas)
    sorted_texts = sorted(book_texts, key=lambda b: b['y'])
    all_texts = [b['text'].strip() for b in sorted_texts]
    combined = ' / '.join(all_texts)

    # Limitation de longueur
    return combined[:60] + '...' if len(combined) > 60 else combined
```

---

## üöÄ **Script de d√©tection principal**

Le script `ocr_detect.py` fournit l'interface utilisateur :

```python
def main():
    # 1. Parsing des arguments
    parser = argparse.ArgumentParser(description='ShelfReader - D√©tection OCR de livres')
    parser.add_argument('image_path', help='Chemin vers l\'image √† analyser')
    parser.add_argument('--gpu', action='store_true', help='Utiliser le GPU')
    parser.add_argument('--easyocr', action='store_true', help='Utiliser EasyOCR')
    parser.add_argument('--tesseract', action='store_true', help='Utiliser Tesseract')

    args = parser.parse_args()

    # 2. Validation
    if args.easyocr and args.tesseract:
        print("‚ùå Erreur: Impossible d'utiliser les deux moteurs")
        sys.exit(1)

    # 3. Configuration des imports
    script_dir = Path(__file__).parent
    src_dir = script_dir.parent / "src"
    sys.path.insert(0, str(src_dir))

    # 4. Initialisation et traitement
    from ocr_processor import BookOCR
    processor = BookOCR(['en'], 0.2, use_gpu=args.gpu, use_tesseract=args.tesseract)

    pil_image = Image.open(args.image_path)

    # 5. Analyse
    text, confidence = processor.get_text_and_confidence(pil_image, preprocess=False)
    boxes = processor.get_boxes(pil_image, preprocess=False)
    books = processor.get_books(pil_image, preprocess=False)

    # 6. Affichage des r√©sultats
    print(f"üìä R√©sultats:")
    print(f"   Textes d√©tect√©s: {len(boxes)}")
    print(f"   Livres d√©tect√©s: {len(books)}")
    print(f"   Confiance: {confidence:.2f}")

    for i, book in enumerate(books, 1):
        print(f"   {i:2d}. {book['title']}")
```

---

## ÔøΩ **Interactions entre m√©thodes**

### **M√©thodes publiques principales**

La classe `BookOCR` expose **3 m√©thodes publiques principales** qui s'appellent hi√©rarchiquement :

```python
# Niveau 1 : M√©thode principale appel√©e par l'utilisateur
def get_books(self, pil_image, preprocess=True):
    boxes = self.get_boxes(pil_image, preprocess=preprocess, vertical_only=False)
    books = self.group_by_books(boxes)
    return books

# Niveau 2 : Extraction des bo√Ætes de texte
def get_boxes(self, pil_image, preprocess=False, vertical_only=False):
    # Appelle _tesseract_detect() ou self.reader.readtext()
    # Appelle _is_vertical_text() et _calculate_font_size()
    return boxes

# Niveau 3 : D√©tection brute du texte
def get_text_and_confidence(self, pil_image, preprocess=True):
    # Appelle _preprocess_image() si preprocess=True
    # Appelle _tesseract_detect() ou self.reader.readtext()
    return text, confidence
```

### **Arbre d'appels des m√©thodes**

```
get_books()                    # Point d'entr√©e principal
‚îú‚îÄ‚îÄ get_boxes()               # Extraction coordonn√©es
‚îÇ   ‚îú‚îÄ‚îÄ _tesseract_detect()   # OU reader.readtext() (EasyOCR)
‚îÇ   ‚îú‚îÄ‚îÄ _is_vertical_text()   # D√©tection orientation
‚îÇ   ‚îî‚îÄ‚îÄ _calculate_font_size() # Calcul taille police
‚îú‚îÄ‚îÄ group_by_books()          # Regroupement spatial
‚îÇ   ‚îî‚îÄ‚îÄ _extract_book_title() # Reconstruction titre
‚îî‚îÄ‚îÄ get_text_and_confidence() # Texte + confiance (optionnel)
    ‚îú‚îÄ‚îÄ _preprocess_image()   # Pr√©traitement
    ‚îî‚îÄ‚îÄ _tesseract_detect()   # OU reader.readtext()
```

### **D√©pendances entre m√©thodes**

#### **M√©thodes utilitaires** (appel√©es par plusieurs autres) :
- **`_is_vertical_text(bbox)`** : D√©tecte si texte vertical
  - **Utilis√©e par** : `get_boxes()`, `group_by_books()`
  - **Raison** : D√©cision d'inclure/exclure des textes

- **`_calculate_font_size(bbox)`** : Calcule taille approximative
  - **Utilis√©e par** : `get_boxes()`
  - **Raison** : Filtrage par taille de police

- **`_preprocess_image(image)`** : Am√©liore qualit√© image
  - **Utilis√©e par** : `get_text_and_confidence()`, `get_boxes()`
  - **Raison** : Am√©liorer pr√©cision OCR

#### **M√©thodes de d√©tection OCR** :
- **`_tesseract_detect(pil_image)`** : D√©tection avec Tesseract
  - **Utilis√©e par** : `get_text_and_confidence()`, `get_boxes()`
  - **Condition** : `self.use_tesseract == True`

- **`self.reader.readtext()`** : D√©tection avec EasyOCR
  - **Utilis√©e par** : `get_text_and_confidence()`, `get_boxes()`
  - **Condition** : `self.use_tesseract == False`

### **Flux de donn√©es interne**

```python
# Exemple d'appel get_books()
def get_books(self, pil_image, preprocess=True):
    # 1. Obtenir TOUTES les bo√Ætes de texte
    all_boxes = self.get_boxes(pil_image, preprocess=preprocess, vertical_only=False)
    #    ‚Üì
    #    get_boxes() appelle get_text_and_confidence() ou _tesseract_detect()
    #    qui peut appeler _preprocess_image()
    
    # 2. Regrouper spatialement
    books = self.group_by_books(all_boxes)
    #    ‚Üì
    #    group_by_books() appelle _extract_book_title()
    #    qui utilise _is_vertical_text()
    
    return books
```

---

## üîó **Interactions entre fichiers**

### **Relation `ocr_detect.py` ‚Üí `ocr_processor.py`**

Le script `ocr_detect.py` est le **point d'entr√©e utilisateur** qui **configure et utilise** `BookOCR` :

```python
# ocr_detect.py
def main():
    # 1. PARSING DES ARGUMENTS UTILISATEUR
    args = parser.parse_args()  # --gpu, --tesseract, etc.
    
    # 2. CONFIGURATION DU CHEMIN D'IMPORT
    script_dir = Path(__file__).parent          # scripts/
    src_dir = script_dir.parent / "src"         # src/
    sys.path.insert(0, str(src_dir))            # Ajoute src/ au PYTHONPATH
    
    # 3. IMPORT DE LA CLASSE
    from ocr_processor import BookOCR           # Import depuis src/
    
    # 4. INSTANCIATION AVEC PARAM√àTRES UTILISATEUR
    processor = BookOCR(
        ['en'],                    # langues
        0.2,                       # seuil confiance
        use_gpu=args.gpu,          # option GPU
        use_tesseract=args.tesseract  # moteur OCR
    )
    
    # 5. UTILISATION DES M√âTHODES
    pil_image = Image.open(args.image_path)
    
    # Appel s√©quentiel des m√©thodes de BookOCR
    text, confidence = processor.get_text_and_confidence(pil_image, preprocess=False)
    boxes = processor.get_boxes(pil_image, preprocess=False)
    books = processor.get_books(pil_image, preprocess=False)
    
    # 6. AFFICHAGE DES R√âSULTATS
    print(f"üìä R√©sultats: {len(boxes)} textes, {len(books)} livres")
```

### **Responsabilit√©s s√©par√©es**

#### **`ocr_detect.py`** (Couche Interface)
- **Parsing** des arguments utilisateur
- **Configuration** de l'environnement Python
- **Gestion des erreurs** utilisateur
- **Affichage** des r√©sultats format√©s
- **Validation** des fichiers d'entr√©e

#### **`ocr_processor.py`** (Couche M√©tier)
- **Logique OCR** pure (d√©tection, pr√©traitement)
- **Algorithmes** de regroupement
- **Calculs** math√©matiques et g√©om√©triques
- **Gestion** des moteurs OCR (EasyOCR/Tesseract)

### **Avantages de la s√©paration**

1. **R√©utilisabilit√©** : `BookOCR` peut √™tre utilis√© dans d'autres scripts/interfaces
2. **Testabilit√©** : Logique m√©tier testable ind√©pendamment de l'interface
3. **Maintenabilit√©** : Changements d'interface sans toucher la logique OCR
4. **√âvolutivit√©** : Possibilit√© d'ajouter une interface web sans changer `BookOCR`

### **Configuration des imports**

```python
# ocr_detect.py - Configuration des imports
script_dir = Path(__file__).parent      # /path/to/scripts/
src_dir = script_dir.parent / "src"     # /path/to/src/
sys.path.insert(0, str(src_dir))        # Ajoute /path/to/src/ au PYTHONPATH

from ocr_processor import BookOCR       # Import depuis src/ocr_processor.py
```

**Pourquoi cette configuration ?**
- Les scripts sont dans `scripts/`, la classe dans `src/`
- Python ne trouve pas automatiquement `src/` depuis `scripts/`
- `sys.path.insert(0, str(src_dir))` ajoute `src/` au chemin de recherche

---

## ‚ö° **Flux d'ex√©cution d√©taill√©**

### **Sc√©nario complet : Analyse d'une image**

```bash
python scripts/ocr_detect.py --gpu test_images/books1.jpg
```

#### **Phase 1 : Initialisation (ocr_detect.py)**

```python
# 1. Parsing arguments
args = parser.parse_args()
# R√©sultat : image_path="test_images/books1.jpg", gpu=True, tesseract=False

# 2. Validation fichier
if not os.path.exists("test_images/books1.jpg"):
    print("‚ùå Image introuvable")
    sys.exit(1)

# 3. Configuration imports
script_dir = Path(__file__).parent      # scripts/
src_dir = script_dir.parent / "src"     # src/
sys.path.insert(0, str(src_dir))        # PYTHONPATH += src/

# 4. Import classe
from ocr_processor import BookOCR

# 5. Cr√©ation instance
processor = BookOCR(['en'], 0.2, use_gpu=True, use_tesseract=False)
# ‚Üì Appelle BookOCR.__init__()
```

#### **Phase 2 : Initialisation BookOCR**

```python
# BookOCR.__init__()
def __init__(self, languages, confidence_threshold, use_gpu=False, use_tesseract=False):
    self.use_tesseract = False
    self.confidence_threshold = 0.2
    
    # Initialisation EasyOCR avec GPU
    self.reader = easyocr.Reader(['en'], gpu=True)
    print("üîç OCR initialis√© - EasyOCR, Langues: ['en'], Seuil: 0.2, Device: GPU")
```

#### **Phase 3 : Chargement de l'image**

```python
# ocr_detect.py
pil_image = Image.open("test_images/books1.jpg")
# R√©sultat : Objet PIL.Image avec l'image charg√©e
```

#### **Phase 4 : Analyse OCR (get_text_and_confidence)**

```python
# ocr_detect.py
text, confidence = processor.get_text_and_confidence(pil_image, preprocess=False)

# ‚Üì D√©tail de l'appel
def get_text_and_confidence(self, pil_image, preprocess=False):
    # Conversion PIL ‚Üí NumPy ‚Üí BGR
    image_array = np.array(pil_image)
    bgr_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)
    
    # PAS de pr√©traitement (preprocess=False)
    
    # D√©tection EasyOCR
    results = self.reader.readtext(bgr_image, rotation_info=[0, 90, 180, 270])
    
    # Filtrage
    filtered_results = [
        r for r in results
        if r[2] >= 0.2 and len(r[1].strip()) >= 2
    ]
    
    # Agr√©gation
    texts = [r[1] for r in filtered_results]
    confidences = [r[2] for r in filtered_results]
    
    full_text = ' '.join(texts)
    avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
    
    return full_text, avg_confidence
```

#### **Phase 5 : Extraction des bo√Ætes (get_boxes)**

```python
# ocr_detect.py
boxes = processor.get_boxes(pil_image, preprocess=False)

# ‚Üì D√©tail de l'appel
def get_boxes(self, pil_image, preprocess=False, vertical_only=False):
    # M√™me d√©tection OCR que ci-dessus
    results = self.reader.readtext(bgr_image, rotation_info=[0, 90, 180, 270])
    
    boxes = []
    for bbox, text, confidence in results:
        if confidence >= 0.2 and len(text.strip()) >= 2:
            # Calcul dimensions
            x = min([p[0] for p in bbox])
            y = min([p[1] for p in bbox])
            width = max([p[0] for p in bbox]) - x
            height = max([p[1] for p in bbox]) - y
            font_size = self._calculate_font_size(bbox)
            
            # D√©tection verticale
            is_vertical = self._is_vertical_text(bbox)
            
            boxes.append({
                "text": text, "x": x, "y": y, "width": width, "height": height,
                "font_size": font_size, "is_vertical": is_vertical
            })
    
    return boxes
```

#### **Phase 6 : Regroupement par livres (get_books)**

```python
# ocr_detect.py
books = processor.get_books(pil_image, preprocess=False)

# ‚Üì D√©tail de l'appel
def get_books(self, pil_image, preprocess=True):
    # 1. Obtenir toutes les bo√Ætes
    boxes = self.get_boxes(pil_image, preprocess=preprocess, vertical_only=False)
    
    # 2. Regrouper par livres
    books = self.group_by_books(boxes)
    
    return books

# ‚Üì group_by_books() en d√©tail
def group_by_books(self, boxes, vertical_threshold=50):
    # 1. Filtrer vertical + grandes polices
    vertical_boxes = [b for b in boxes if b.get('is_vertical', False)]
    font_sizes = [b['font_size'] for b in vertical_boxes]
    median_font_size = sorted(font_sizes)[len(font_sizes) // 2]
    large_text_boxes = [b for b in vertical_boxes if b['font_size'] >= median_font_size * 0.8]
    
    # 2. Trier par position X
    sorted_boxes = sorted(large_text_boxes, key=lambda b: b['x'])
    
    # 3. Regrouper spatialement
    books = []
    current_book = [sorted_boxes[0]]
    current_x = sorted_boxes[0]['x']
    
    for box in sorted_boxes[1:]:
        if abs(box['x'] - current_x) <= 50:  # Seuil de 50px
            current_book.append(box)
        else:
            books.append(current_book)
            current_book = [box]
            current_x = box['x']
    
    if current_book:
        books.append(current_book)
    
    # 4. Extraire titres
    formatted_books = []
    for book_texts in books:
        title = self._extract_book_title(book_texts)
        formatted_books.append({
            'title': title,
            'x': book_texts[0]['x'],
            'all_texts': [b['text'] for b in book_texts],
            'text_count': len(book_texts)
        })
    
    return formatted_books
```

#### **Phase 7 : Affichage des r√©sultats**

```python
# ocr_detect.py
print(f"\nüìä R√©sultats:")
print(f"   Textes d√©tect√©s: {len(boxes)}")
print(f"   Livres d√©tect√©s: {len(books)}")
print(f"   Confiance: {confidence:.2f}")
print(f"   Texte: {text[:80]}{'...' if len(text) > 80 else ''}")

if books:
    print(f"\nüìö Livres d√©tect√©s ({len(books)}):")
    for i, book in enumerate(books, 1):
        print(f"   {i:2d}. {book['title']}")
        if book['text_count'] > 1:
            other_texts = ', '.join(book['all_texts'][:3])
            print(f"       ‚îî‚îÄ (+{book['text_count']-1} textes: {other_texts})")

print("\n‚úÖ Analyse termin√©e!")
```

### **Temps d'ex√©cution approximatif**

- **Initialisation EasyOCR** : 5-10 secondes (chargement mod√®le)
- **Chargement image** : < 1 seconde
- **D√©tection OCR** : 2-5 secondes (d√©pend de la taille image/GPU)
- **Regroupement** : < 1 seconde
- **Affichage** : < 1 seconde

**Total** : 8-17 secondes pour une premi√®re analyse

---

## üîÑ **R√©sum√© des interactions**

### **Hi√©rarchie des appels**
```
Utilisateur
    ‚Üì
ocr_detect.py::main()
    ‚Üì (import + instanciation)
BookOCR.__init__()
    ‚Üì (utilisation)
BookOCR.get_books()
    ‚îú‚îÄ‚îÄ BookOCR.get_boxes()
    ‚îÇ   ‚îú‚îÄ‚îÄ BookOCR._is_vertical_text()
    ‚îÇ   ‚îú‚îÄ‚îÄ BookOCR._calculate_font_size()
    ‚îÇ   ‚îî‚îÄ‚îÄ BookOCR.reader.readtext() [EasyOCR]
    ‚îî‚îÄ‚îÄ BookOCR.group_by_books()
        ‚îî‚îÄ‚îÄ BookOCR._extract_book_title()
```

### **Flux de donn√©es**
```
Arguments utilisateur ‚Üí Parsing ‚Üí Configuration ‚Üí Instanciation BookOCR
                                                                    ‚Üì
Image PIL ‚Üí get_books() ‚Üí get_boxes() ‚Üí OCR Engine ‚Üí Boxes filtr√©es
                                                                 ‚Üì
Boxes filtr√©es ‚Üí group_by_books() ‚Üí Regroupement spatial ‚Üí Livres
                                                                 ‚Üì
Livres ‚Üí Affichage format√© ‚Üí Utilisateur
```

### **Points de d√©cision**
- **Moteur OCR** : `use_tesseract` (Tesseract vs EasyOCR)
- **Acc√©l√©ration** : `use_gpu` (GPU vs CPU)
- **Pr√©traitement** : Param√®tre `preprocess` dans certaines m√©thodes
- **Filtrage vertical** : Param√®tre `vertical_only` dans `get_boxes()`

Cette architecture modulaire permet de **tester chaque composant ind√©pendamment** et de **r√©utiliser** la logique OCR dans diff√©rents contextes (interface web, API, etc.).

### √âtape 1 : Installation des d√©pendances

```bash
pip install easyocr opencv-python pillow pytesseract numpy torch torchvision
```

### √âtape 2 : Structure des fichiers

```
mon_projet_ocr/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ ocr_processor.py    # Classe BookOCR
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ ocr_detect.py       # Script principal
‚îî‚îÄ‚îÄ test_images/
    ‚îî‚îÄ‚îÄ books.jpg          # Image de test
```

### √âtape 3 : Classe BookOCR de base

```python
import easyocr
import cv2
import numpy as np
from PIL import Image

class BookOCR:
    def __init__(self, languages, confidence_threshold, use_gpu=False):
        self.confidence_threshold = confidence_threshold
        self.reader = easyocr.Reader(languages, gpu=use_gpu)

    def get_text_and_confidence(self, pil_image, preprocess=True):
        image_array = np.array(pil_image)
        bgr_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)

        results = self.reader.readtext(bgr_image, rotation_info=[0, 90, 180, 270])

        filtered_results = [
            r for r in results
            if r[2] >= self.confidence_threshold and len(r[1].strip()) >= 2
        ]

        texts = [r[1] for r in filtered_results]
        confidences = [r[2] for r in filtered_results]

        full_text = ' '.join(texts)
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0

        return full_text, avg_confidence

    def get_boxes(self, pil_image, preprocess=False):
        image_array = np.array(pil_image)
        bgr_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)

        results = self.reader.readtext(bgr_image, rotation_info=[0, 90, 180, 270])

        boxes = []
        for bbox, text, confidence in results:
            if confidence >= self.confidence_threshold and len(text.strip()) >= 2:
                x = min([p[0] for p in bbox])
                y = min([p[1] for p in bbox])
                width = max([p[0] for p in bbox]) - x
                height = max([p[1] for p in bbox]) - y

                boxes.append({
                    "text": text,
                    "x": x, "y": y,
                    "width": width, "height": height,
                    "is_vertical": height > width * 1.5
                })

        return boxes

    def get_books(self, pil_image, preprocess=True):
        boxes = self.get_boxes(pil_image, preprocess=preprocess)
        # Version simplifi√©e : retourner tous les textes verticaux comme "livres"
        vertical_boxes = [b for b in boxes if b['is_vertical']]
        return [{
            'title': box['text'],
            'x': box['x'],
            'all_texts': [box['text']],
            'text_count': 1
        } for box in vertical_boxes]
```

### √âtape 4 : Script de test

```python
#!/usr/bin/env python3
import sys
import os
from pathlib import Path

# Configuration des imports
script_dir = Path(__file__).parent
src_dir = script_dir.parent / "src"
sys.path.insert(0, str(src_dir))

from ocr_processor import BookOCR
from PIL import Image

def main():
    if len(sys.argv) != 2:
        print("Usage: python ocr_detect.py <image_path>")
        sys.exit(1)

    image_path = sys.argv[1]

    if not os.path.exists(image_path):
        print(f"Image not found: {image_path}")
        sys.exit(1)

    # Initialisation
    processor = BookOCR(['en'], 0.2, use_gpu=False)

    # Traitement
    pil_image = Image.open(image_path)
    text, confidence = processor.get_text_and_confidence(pil_image, preprocess=False)
    boxes = processor.get_boxes(pil_image, preprocess=False)
    books = processor.get_books(pil_image, preprocess=False)

    # R√©sultats
    print(f"üìä R√©sultats:")
    print(f"   Textes d√©tect√©s: {len(boxes)}")
    print(f"   Livres d√©tect√©s: {len(books)}")
    print(f"   Confiance: {confidence:.2f}")
    print(f"   Texte: {text[:80]}{'...' if len(text) > 80 else ''}")

    if books:
        print(f"\nüìö Livres d√©tect√©s:")
        for i, book in enumerate(books, 1):
            print(f"   {i}. {book['title']}")

if __name__ == "__main__":
    main()
```

### √âtape 5 : Am√©liorations progressives

1. **Ajouter le pr√©traitement d'image**
2. **Impl√©menter la d√©tection verticale**
3. **Ajouter le regroupement par livres**
4. **Int√©grer Tesseract comme alternative**
5. **Ajouter les options GPU/CPU**
6. **Am√©liorer la reconstruction des titres**

### √âtape 6 : Test et validation

```bash
# Test basique
python scripts/ocr_detect.py test_images/books.jpg

# Avec GPU
python scripts/ocr_detect.py --gpu test_images/books.jpg

# Avec Tesseract
python scripts/ocr_detect.py --tesseract test_images/books.jpg
```

---

## üéØ **Points cl√©s pour r√©ussir**

### 1. **Comprendre les d√©fis**
- Texte vertical sur tranches de livres
- Contraste et qualit√© variables
- Petits caract√®res difficiles √† d√©tecter

### 2. **Choisir le bon moteur OCR**
- **EasyOCR** : Plus pr√©cis, supporte les rotations
- **Tesseract** : Plus rapide, meilleur pour texte simple

### 3. **Optimiser le pr√©traitement**
- CLAHE pour am√©liorer le contraste
- Filtres pour r√©duire le bruit
- Binarisation adaptative

### 4. **Algorithme de regroupement**
- D√©tecter le texte vertical
- Filtrer par taille de police
- Regrouper spatialement
- Reconstruire les titres

### 5. **Gestion des erreurs**
- Validation des fichiers d'entr√©e
- Gestion des imports manquants
- Messages d'erreur informatifs

---

*Ce document vous donne toutes les cl√©s pour comprendre et recr√©er le syst√®me OCR de ShelfReader. Commencez par la version simplifi√©e, puis ajoutez progressivement les fonctionnalit√©s avanc√©es.*</content>
<parameter name="filePath">/home/delart/Documents/dev/python/Shelfreader/p1-MVP-Desktop/docs/OCR_Code_Explanation.md