# üîç **OCR Code Explanation - ShelfReader P1**
## Comprendre et recr√©er le syst√®me OCR de d√©tection de livres

*Ce document explique en d√©tail le code OCR de ShelfReader P1, vous permettant de comprendre chaque concept et de recr√©er le syst√®me de z√©ro.*

---

## üìã **Table des mati√®res**
1. [Architecture g√©n√©rale](#architecture-g√©n√©rale)
2. [Concepts OCR fondamentaux](#concepts-ocr-fondamentaux)
3. [Architecture modulaire OCR](#architecture-modulaire-ocr)
4. [Module EasyOCR](#module-easyocr)
5. [Module Tesseract](#module-tesseract)
6. [Module TrOCR](#module-trocr)
7. [Script de d√©tection unifi√©](#script-de-d√©tection-unifi√©)
8. [Pr√©traitement d'image](#pr√©traitement-dimage)
9. [Extraction des bo√Ætes de texte](#extraction-des-bo√Ætes-de-texte)
10. [Regroupement par livres](#regroupement-par-livres)
11. [Interactions entre modules](#interactions-entre-modules)
12. [Flux d'ex√©cution d√©taill√©](#flux-dex√©cution-d√©taill√©)
13. [Comment utiliser le syst√®me](#comment-utiliser-le-syst√®me)

---

## üèóÔ∏è **Architecture g√©n√©rale**

Le syst√®me OCR de ShelfReader P1 utilise une **architecture modulaire** compos√©e de **quatre fichiers principaux** :

### Moteurs OCR individuels
- **`src/ocr_easyocr.py`** : Module EasyOCR avec GPU support
  - **Classe** : `EasyOCRProcessor`
  - **Sp√©cialisation** : D√©tection pr√©cise avec rotations automatiques
- **`src/ocr_tesseract.py`** : Module Tesseract avec configurations PSM
  - **Classe** : `TesseractOCRProcessor`
  - **Sp√©cialisation** : Performance et texte horizontal
- **`src/ocr_trocr.py`** : Module TrOCR avec transformers
  - **Classe** : `TrOCRProcessor`
  - **Sp√©cialisation** : Mod√®le transformer avanc√©

### Script unifi√©
- **`scripts/ocr_detect.py`** : Interface en ligne de commande unifi√©e
- **Responsabilit√©s** :
  - Parsing des arguments
  - S√©lection du moteur OCR
  - Configuration du syst√®me
  - Affichage des r√©sultats
  - Gestion des erreurs

### Flux de donn√©es :
```
Image ‚Üí S√©lection moteur ‚Üí Pr√©traitement ‚Üí D√©tection OCR ‚Üí Bo√Ætes de texte ‚Üí Regroupement ‚Üí Livres d√©tect√©s
```

### Avantages de l'architecture modulaire :
1. **Ind√©pendance** : Chaque moteur peut √™tre test√© et utilis√© s√©par√©ment
2. **Maintenance** : Modifications isol√©es par moteur
3. **Performance** : Choix du moteur optimal selon les besoins
4. **√âvolutivit√©** : Ajout de nouveaux moteurs facile

---

## üéØ **Concepts OCR fondamentaux**

### Qu'est-ce que l'OCR ?
L'**OCR (Optical Character Recognition)** est la technologie qui permet de **convertir des images de texte en texte num√©rique**.

### D√©fis sp√©cifiques aux tranches de livres :
1. **Texte vertical** : Les titres sont √©crits verticalement sur les tranches
2. **Petite taille** : Texte souvent petit et fin
3. **Contraste variable** : Qualit√© d'impression in√©gale
4. **D√©formation** : Courbure des tranches de livres

### Moteurs OCR utilis√©s :

#### EasyOCR
- **Avantages** : D√©tection automatique des rotations, tr√®s pr√©cis, GPU support
- **Inconv√©nients** : Plus lent au chargement, n√©cessite PyTorch
- **Usage** : Texte complexe, rotations multiples, pr√©cision maximale

#### Tesseract
- **Avantages** : Rapide, l√©ger, configurations PSM avanc√©es
- **Inconv√©nients** : Moins bon avec les rotations complexes
- **Usage** : Texte simple, performance importante, CPU uniquement

#### TrOCR (Transformer OCR)
- **Avantages** : Mod√®le de deep learning avanc√©, excellente pr√©cision
- **Inconv√©nients** : Lent, n√©cessite beaucoup de ressources
- **Usage** : Haute pr√©cision requise, GPU recommand√©

---

## üèóÔ∏è **Architecture modulaire OCR**

Le syst√®me utilise une architecture modulaire o√π chaque moteur OCR est encapsul√© dans sa propre classe :

### Interface commune
Tous les modules OCR impl√©mentent une interface similaire :
- `__init__(confidence_threshold, use_gpu=False)` : Initialisation
- `detect_text(image_path)` : D√©tection principale
- `get_text_and_confidence(pil_image)` : Texte + confiance
- CLI int√©gr√© avec `argparse` pour utilisation standalone

### Structure des modules
```
src/
‚îú‚îÄ‚îÄ ocr_easyocr.py     # EasyOCRProcessor
‚îú‚îÄ‚îÄ ocr_tesseract.py   # TesseractOCRProcessor
‚îî‚îÄ‚îÄ ocr_trocr.py       # TrOCRProcessor
```

### Gestion des d√©pendances
- **EasyOCR** : `easyocr`, `torch`, `torchvision`
- **Tesseract** : `pytesseract`, `tesseract` system package
- **TrOCR** : `transformers`, `torch`

### Avantages modulaires
1. **Testabilit√©** : Chaque moteur testable ind√©pendamment
2. **Performance** : Choix du moteur selon les besoins
3. **Maintenance** : Modifications isol√©es
4. **Extensibilit√©** : Nouveaux moteurs faciles √† ajouter

---

## üîß **Module EasyOCR**

Le module `ocr_easyocr.py` encapsule le moteur EasyOCR :

```python
class EasyOCRProcessor:
    def __init__(self, confidence_threshold=0.2, use_gpu=True):
        self.confidence_threshold = confidence_threshold
        self.reader = easyocr.Reader(['en'], gpu=use_gpu)
        print(f"üîç EasyOCR initialis√© - Seuil: {confidence_threshold}, GPU: {use_gpu}")

    def detect_text(self, image_path):
        # Chargement et traitement de l'image
        pil_image = Image.open(image_path)
        return self.get_text_and_confidence(pil_image)

    def get_text_and_confidence(self, pil_image):
        # Conversion et d√©tection OCR
        image_array = np.array(pil_image)
        bgr_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)

        results = self.reader.readtext(bgr_image, rotation_info=[0, 90, 180, 270])
        filtered_results = [r for r in results if r[2] >= self.confidence_threshold]

        texts = [r[1] for r in filtered_results]
        avg_confidence = np.mean([r[2] for r in filtered_results]) if filtered_results else 0.0

        return ' '.join(texts), avg_confidence
```

### Utilisation standalone :
```bash
python src/ocr_easyocr.py --image path/to/image.jpg --gpu
```

---

## üìù **Module Tesseract**

Le module `ocr_tesseract.py` utilise Tesseract avec configurations PSM :

```python
class TesseractOCRProcessor:
    def __init__(self, confidence_threshold=0.3, psm_mode=6):
        self.confidence_threshold = confidence_threshold
        self.psm_mode = psm_mode
        self.tesseract_config = f'--oem 3 --psm {psm_mode} -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ...'
        print(f"üîç Tesseract initialis√© - Seuil: {confidence_threshold}, PSM: {psm_mode}")

    def detect_text(self, image_path):
        pil_image = Image.open(image_path)
        return self.get_text_and_confidence(pil_image)

    def get_text_and_confidence(self, pil_image):
        # Pr√©traitement et d√©tection
        image_array = np.array(pil_image)
        gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)

        data = pytesseract.image_to_data(gray, config=self.tesseract_config, output_type=pytesseract.Output.DICT)

        results = []
        for i in range(len(data['text'])):
            if int(data['conf'][i]) > 0:
                text = data['text'][i].strip()
                confidence = int(data['conf'][i]) / 100.0
                if confidence >= self.confidence_threshold and len(text) >= 2:
                    results.append((text, confidence))

        texts = [text for text, conf in results]
        avg_confidence = np.mean([conf for text, conf in results]) if results else 0.0

        return ' '.join(texts), avg_confidence
```

### Utilisation standalone :
```bash
python src/ocr_tesseract.py --image path/to/image.jpg --psm 6
```

---

## ü§ñ **Module TrOCR**

Le module `ocr_trocr.py` utilise le mod√®le Transformer TrOCR :

```python
class TrOCRProcessor:
    def __init__(self, confidence_threshold=0.5, use_gpu=True):
        self.confidence_threshold = confidence_threshold
        self.device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')

        self.processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-printed')
        self.model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-printed')
        self.model.to(self.device)

        print(f"üîç TrOCR initialis√© - Seuil: {confidence_threshold}, Device: {self.device}")

    def detect_text(self, image_path):
        pil_image = Image.open(image_path)
        return self.get_text_and_confidence(pil_image)

    def get_text_and_confidence(self, pil_image):
        # Pr√©traitement et g√©n√©ration
        pixel_values = self.processor(pil_image, return_tensors="pt").pixel_values
        pixel_values = pixel_values.to(self.device)

        generated_ids = self.model.generate(
            pixel_values,
            max_length=50,
            num_beams=4,
            early_stopping=True
        )

        generated_text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
        confidence = self._estimate_confidence(pixel_values, generated_ids)

        return generated_text, confidence
```

### Utilisation standalone :
```bash
python src/ocr_trocr.py --image path/to/image.jpg --gpu
```

### Configuration Tesseract :
```python
self.tesseract_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ...'
```
- `--oem 3` : Mode moteur par d√©faut
- `--psm 6` : Assume un bloc uniforme de texte
- `tessedit_char_whitelist` : Limite aux caract√®res alphanum√©riques

---

## üñºÔ∏è **Pr√©traitement d'image**

Le pr√©traitement am√©liore drastiquement la qualit√© de d√©tection OCR :

```python
def _preprocess_image(self, image):
    # 1. Conversion en niveaux de gris
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # 2. Am√©lioration du contraste (CLAHE)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(6,6))
    enhanced = clahe.apply(gray)

    # 3. R√©duction du bruit
    denoised = cv2.bilateralFilter(enhanced, 9, 75, 75)

    # 4. Am√©lioration de la nettet√©
    gaussian = cv2.GaussianBlur(denoised, (0, 0), 1.0)
    sharpened = cv2.addWeighted(denoised, 1.5, gaussian, -0.5, 0)

    # 5. Binarisation adaptative
    binary = cv2.adaptiveThreshold(sharpened, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 7, 3)

    # 6. Dilatation l√©g√®re
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))
    dilated = cv2.dilate(binary, kernel, iterations=1)

    return cv2.cvtColor(dilated, cv2.COLOR_GRAY2BGR)
```

### √âtapes du pr√©traitement :

#### 1. **Conversion en niveaux de gris**
```python
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
```
**Pourquoi ?** L'OCR fonctionne mieux sur des images en noir et blanc.

#### 2. **CLAHE (Contrast Limited Adaptive Histogram Equalization)**
```python
clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(6,6))
enhanced = clahe.apply(gray)
```
**Pourquoi ?** Am√©liore le contraste localement sans amplifier le bruit.

#### 3. **Filtre bilat√©ral**
```python
denoised = cv2.bilateralFilter(enhanced, 9, 75, 75)
```
**Pourquoi ?** R√©duit le bruit tout en pr√©servant les bords des caract√®res.

#### 4. **Unsharp masking**
```python
gaussian = cv2.GaussianBlur(denoised, (0, 0), 1.0)
sharpened = cv2.addWeighted(denoised, 1.5, gaussian, -0.5, 0)
```
**Pourquoi ?** Augmente la nettet√© des caract√®res.

#### 5. **Binarisation adaptative**
```python
binary = cv2.adaptiveThreshold(sharpened, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 7, 3)
```
**Pourquoi ?** Convertit en noir/blanc en s'adaptant aux variations d'√©clairage.

#### 6. **Dilatation**
```python
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))
dilated = cv2.dilate(binary, kernel, iterations=1)
```
**Pourquoi ?** Connecte les parties des caract√®res qui ont √©t√© s√©par√©es.

---

## üîç **D√©tection de texte avec EasyOCR**

EasyOCR est le moteur OCR principal :

```python
def get_text_and_confidence(self, pil_image, preprocess=True):
    # Conversion PIL ‚Üí NumPy ‚Üí BGR
    image_array = np.array(pil_image)
    bgr_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)

    # Pr√©traitement si demand√©
    if preprocess:
        bgr_image = self._preprocess_image(bgr_image)

    # D√©tection OCR avec param√®tres optimis√©s
    results = self.reader.readtext(
        bgr_image,
        rotation_info=[0, 90, 180, 270],  # D√©tecte toutes les orientations
        width_ths=0.3,      # Tol√©rance largeur
        height_ths=0.3,     # Tol√©rance hauteur
        contrast_ths=0.05,  # Seuil contraste tr√®s bas
        adjust_contrast=0.7, # Ajustement contraste
        text_threshold=0.5,  # Seuil d√©tection texte
        link_threshold=0.3   # Seuil liaison caract√®res
    )

    # Filtrage par confiance et longueur
    filtered_results = [
        r for r in results
        if r[2] >= self.confidence_threshold and len(r[1].strip()) >= 2
    ]

    return ' '.join([r[1] for r in filtered_results]), np.mean([r[2] for r in filtered_results])
```

### Param√®tres EasyOCR importants :

- **`rotation_info`** : D√©tecte le texte dans toutes les orientations
- **`width_ths/height_ths`** : Tol√©rance aux variations de taille
- **`contrast_ths`** : Sensibilit√© au contraste (tr√®s bas pour texte fin)
- **`text_threshold`** : Seuil de confiance pour consid√©rer du texte

### Format des r√©sultats EasyOCR :
```python
[
    [[[x1,y1], [x2,y2], [x3,y3], [x4,y4]], "texte d√©tect√©", confiance],
    ...
]
```

---

## üìù **D√©tection de texte avec Tesseract**

Tesseract est utilis√© comme alternative :

```python
def _tesseract_detect(self, pil_image):
    # Conversion et pr√©traitement
    image_array = np.array(pil_image)
    gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)

    # D√©tection avec Tesseract
    data = pytesseract.image_to_data(enhanced, config=self.tesseract_config, output_type=pytesseract.Output.DICT)

    results = []
    for i in range(len(data['text'])):
        text = data['text'][i].strip()
        confidence = int(data['conf'][i]) / 100.0

        if confidence > 0.1 and len(text) >= 2:
            x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]
            bbox = [[x, y], [x+w, y], [x+w, y+h], [x, y+h]]
            results.append([bbox, text, confidence])

    return results
```

### Avantages de Tesseract :
- Plus rapide que EasyOCR
- Meilleur pour le texte horizontal long
- Moins de d√©pendances

### Inconv√©nients :
- Moins performant sur les rotations
- Pr√©configuration n√©cessaire pour le texte vertical

---

## üì¶ **Extraction des bo√Ætes de texte**

La m√©thode `get_boxes()` extrait les coordonn√©es de chaque texte d√©tect√© :

```python
def get_boxes(self, pil_image, preprocess=False, vertical_only=False):
    # D√©tection OCR (EasyOCR ou Tesseract)
    results = self._tesseract_detect(pil_image) if self.use_tesseract else self.reader.readtext(...)

    boxes = []
    for bbox, text, confidence in results:
        # Filtrage de qualit√©
        if confidence < 0.1 or len(text.strip()) < 1:
            continue

        # Calcul des dimensions
        x = min([p[0] for p in bbox])
        y = min([p[1] for p in bbox])
        width = max([p[0] for p in bbox]) - x
        height = max([p[1] for p in bbox]) - y
        font_size = height  # Approximation

        # D√©tection texte vertical
        is_vertical = self._is_vertical_text(bbox)

        if vertical_only and not is_vertical:
            continue

        boxes.append({
            "text": text,
            "x": x, "y": y,
            "width": width, "height": height,
            "font_size": font_size,
            "is_vertical": is_vertical
        })

    return boxes
```

### D√©tection du texte vertical :
```python
def _is_vertical_text(self, bbox):
    width = max([p[0] for p in bbox]) - min([p[0] for p in bbox])
    height = max([p[1] for p in bbox]) - min([p[1] for p in bbox])
    return height > width * 1.5  # Ratio hauteur/largeur > 1.5
```

---

## üìö **Regroupement par livres**

L'algorithme principal regroupe les textes par livre :

```python
def group_by_books(self, boxes, vertical_threshold=50):
    # 1. Filtrer les textes verticaux avec grandes polices
    vertical_boxes = [b for b in boxes if b.get('is_vertical', False)]
    if not vertical_boxes:
        return []

    # 2. Calculer la m√©diane de la taille de police
    font_sizes = [b['font_size'] for b in vertical_boxes]
    median_font_size = sorted(font_sizes)[len(font_sizes) // 2]

    # 3. Garder seulement les grandes polices
    large_text_boxes = [b for b in vertical_boxes if b['font_size'] >= median_font_size * 0.8]

    # 4. Trier par position X (gauche √† droite)
    sorted_boxes = sorted(large_text_boxes, key=lambda b: b['x'])

    # 5. Regrouper par colonnes (m√™me livre)
    books = []
    current_book = [sorted_boxes[0]]
    current_x = sorted_boxes[0]['x']

    for box in sorted_boxes[1:]:
        if abs(box['x'] - current_x) <= vertical_threshold:
            current_book.append(box)  # M√™me livre
        else:
            books.append(current_book)  # Nouveau livre
            current_book = [box]
            current_x = box['x']

    if current_book:
        books.append(current_book)

    # 6. Extraire les titres
    formatted_books = []
    for book_texts in books:
        title = self._extract_book_title(book_texts)
        formatted_books.append({
            'title': title,
            'x': book_texts[0]['x'],
            'all_texts': [b['text'] for b in book_texts],
            'text_count': len(book_texts)
        })

    return formatted_books
```

### Logique de regroupement :

1. **Filtrage vertical** : Seuls les textes verticaux (sur les tranches)
2. **Filtrage par taille** : Les grands textes (titres) vs petits textes (auteurs)
3. **Tri horizontal** : De gauche √† droite dans l'image
4. **Regroupement spatial** : Textes proches horizontalement = m√™me livre
5. **Reconstruction** : Combiner tous les textes d'un livre en titre

### Extraction du titre :
```python
def _extract_book_title(self, book_texts):
    # Trier verticalement (haut vers bas)
    sorted_texts = sorted(book_texts, key=lambda b: b['y'])
    all_texts = [b['text'].strip() for b in sorted_texts]
    combined = ' / '.join(all_texts)

    # Limitation de longueur
    return combined[:60] + '...' if len(combined) > 60 else combined
```

---

## üöÄ **Script de d√©tection unifi√©**

Le script `scripts/ocr_detect.py` orchestre tous les modules OCR :

```python
def main():
    parser = argparse.ArgumentParser(description='ShelfReader - D√©tection OCR unifi√©e')
    parser.add_argument('image_path', help='Chemin vers l\'image')
    parser.add_argument('--engine', choices=['easyocr', 'tesseract', 'trocr'],
                       default='easyocr', help='Moteur OCR √† utiliser')
    parser.add_argument('--gpu', action='store_true', help='Utiliser GPU')
    parser.add_argument('--confidence', type=float, default=0.2,
                       help='Seuil de confiance')

    args = parser.parse_args()

    # S√©lection du processeur selon le moteur choisi
    if args.engine == 'easyocr':
        from src.ocr_easyocr import EasyOCRProcessor
        processor = EasyOCRProcessor(args.confidence, args.gpu)
    elif args.engine == 'tesseract':
        from src.ocr_tesseract import TesseractOCRProcessor
        processor = TesseractOCRProcessor(args.confidence)
    elif args.engine == 'trocr':
        from src.ocr_trocr import TrOCRProcessor
        processor = TrOCRProcessor(args.confidence, args.gpu)

    # Traitement
    text, confidence = processor.detect_text(args.image_path)

    print(f"üìä R√©sultats avec {args.engine}:")
    print(f"   Texte: {text}")
    print(f"   Confiance: {confidence:.2f}")
```

### Utilisation :
```bash
# Avec EasyOCR (d√©faut)
python scripts/ocr_detect.py image.jpg

# Avec Tesseract
python scripts/ocr_detect.py image.jpg --engine tesseract

# Avec TrOCR et GPU
python scripts/ocr_detect.py image.jpg --engine trocr --gpu
```

## ÔøΩ **Interactions entre m√©thodes**

### **M√©thodes publiques principales**

La classe `BookOCR` expose **3 m√©thodes publiques principales** qui s'appellent hi√©rarchiquement :

```python
# Niveau 1 : M√©thode principale appel√©e par l'utilisateur
def get_books(self, pil_image, preprocess=True):
    boxes = self.get_boxes(pil_image, preprocess=preprocess, vertical_only=False)
    books = self.group_by_books(boxes)
    return books

# Niveau 2 : Extraction des bo√Ætes de texte
def get_boxes(self, pil_image, preprocess=False, vertical_only=False):
    # Appelle _tesseract_detect() ou self.reader.readtext()
    # Appelle _is_vertical_text() et _calculate_font_size()
    return boxes

# Niveau 3 : D√©tection brute du texte
def get_text_and_confidence(self, pil_image, preprocess=True):
    # Appelle _preprocess_image() si preprocess=True
    # Appelle _tesseract_detect() ou self.reader.readtext()
    return text, confidence
```

### **Arbre d'appels des m√©thodes**

```
get_books()                    # Point d'entr√©e principal
‚îú‚îÄ‚îÄ get_boxes()               # Extraction coordonn√©es
‚îÇ   ‚îú‚îÄ‚îÄ _tesseract_detect()   # OU reader.readtext() (EasyOCR)
‚îÇ   ‚îú‚îÄ‚îÄ _is_vertical_text()   # D√©tection orientation
‚îÇ   ‚îî‚îÄ‚îÄ _calculate_font_size() # Calcul taille police
‚îú‚îÄ‚îÄ group_by_books()          # Regroupement spatial
‚îÇ   ‚îî‚îÄ‚îÄ _extract_book_title() # Reconstruction titre
‚îî‚îÄ‚îÄ get_text_and_confidence() # Texte + confiance (optionnel)
    ‚îú‚îÄ‚îÄ _preprocess_image()   # Pr√©traitement
    ‚îî‚îÄ‚îÄ _tesseract_detect()   # OU reader.readtext()
```

### **D√©pendances entre m√©thodes**

#### **M√©thodes utilitaires** (appel√©es par plusieurs autres) :
- **`_is_vertical_text(bbox)`** : D√©tecte si texte vertical
  - **Utilis√©e par** : `get_boxes()`, `group_by_books()`
  - **Raison** : D√©cision d'inclure/exclure des textes

- **`_calculate_font_size(bbox)`** : Calcule taille approximative
  - **Utilis√©e par** : `get_boxes()`
  - **Raison** : Filtrage par taille de police

- **`_preprocess_image(image)`** : Am√©liore qualit√© image
  - **Utilis√©e par** : `get_text_and_confidence()`, `get_boxes()`
  - **Raison** : Am√©liorer pr√©cision OCR

#### **M√©thodes de d√©tection OCR** :
- **`_tesseract_detect(pil_image)`** : D√©tection avec Tesseract
  - **Utilis√©e par** : `get_text_and_confidence()`, `get_boxes()`
  - **Condition** : `self.use_tesseract == True`

- **`self.reader.readtext()`** : D√©tection avec EasyOCR
  - **Utilis√©e par** : `get_text_and_confidence()`, `get_boxes()`
  - **Condition** : `self.use_tesseract == False`

### **Flux de donn√©es interne**

```python
# Exemple d'appel get_books()
def get_books(self, pil_image, preprocess=True):
    # 1. Obtenir TOUTES les bo√Ætes de texte
    all_boxes = self.get_boxes(pil_image, preprocess=preprocess, vertical_only=False)
    #    ‚Üì
    #    get_boxes() appelle get_text_and_confidence() ou _tesseract_detect()
    #    qui peut appeler _preprocess_image()
    
    # 2. Regrouper spatialement
    books = self.group_by_books(all_boxes)
    #    ‚Üì
    #    group_by_books() appelle _extract_book_title()
    #    qui utilise _is_vertical_text()
    
    return books
```

---

## üîó **Interactions entre fichiers**

### **Relation `ocr_detect.py` ‚Üí `ocr_processor.py`**

Le script `ocr_detect.py` est le **point d'entr√©e utilisateur** qui **configure et utilise** `BookOCR` :

```python
# ocr_detect.py
def main():
    # 1. PARSING DES ARGUMENTS UTILISATEUR
    args = parser.parse_args()  # --gpu, --tesseract, etc.
    
    # 2. CONFIGURATION DU CHEMIN D'IMPORT
    script_dir = Path(__file__).parent          # scripts/
    src_dir = script_dir.parent / "src"         # src/
    sys.path.insert(0, str(src_dir))            # Ajoute src/ au PYTHONPATH
    
    # 3. IMPORT DE LA CLASSE
    from ocr_processor import BookOCR           # Import depuis src/
    
    # 4. INSTANCIATION AVEC PARAM√àTRES UTILISATEUR
    processor = BookOCR(
        ['en'],                    # langues
        0.2,                       # seuil confiance
        use_gpu=args.gpu,          # option GPU
        use_tesseract=args.tesseract  # moteur OCR
    )
    
    # 5. UTILISATION DES M√âTHODES
    pil_image = Image.open(args.image_path)
    
    # Appel s√©quentiel des m√©thodes de BookOCR
    text, confidence = processor.get_text_and_confidence(pil_image, preprocess=False)
    boxes = processor.get_boxes(pil_image, preprocess=False)
    books = processor.get_books(pil_image, preprocess=False)
    
    # 6. AFFICHAGE DES R√âSULTATS
    print(f"üìä R√©sultats: {len(boxes)} textes, {len(books)} livres")
```

### **Responsabilit√©s s√©par√©es**

#### **`ocr_detect.py`** (Couche Interface)
- **Parsing** des arguments utilisateur
- **Configuration** de l'environnement Python
- **Gestion des erreurs** utilisateur
- **Affichage** des r√©sultats format√©s
- **Validation** des fichiers d'entr√©e

#### **`ocr_processor.py`** (Couche M√©tier)
- **Logique OCR** pure (d√©tection, pr√©traitement)
- **Algorithmes** de regroupement
- **Calculs** math√©matiques et g√©om√©triques
- **Gestion** des moteurs OCR (EasyOCR/Tesseract)

### **Avantages de la s√©paration**

1. **R√©utilisabilit√©** : `BookOCR` peut √™tre utilis√© dans d'autres scripts/interfaces
2. **Testabilit√©** : Logique m√©tier testable ind√©pendamment de l'interface
3. **Maintenabilit√©** : Changements d'interface sans toucher la logique OCR
4. **√âvolutivit√©** : Possibilit√© d'ajouter une interface web sans changer `BookOCR`

### **Configuration des imports**

```python
# ocr_detect.py - Configuration des imports
script_dir = Path(__file__).parent      # /path/to/scripts/
src_dir = script_dir.parent / "src"     # /path/to/src/
sys.path.insert(0, str(src_dir))        # Ajoute /path/to/src/ au PYTHONPATH

from ocr_processor import BookOCR       # Import depuis src/ocr_processor.py
```

**Pourquoi cette configuration ?**
- Les scripts sont dans `scripts/`, la classe dans `src/`
- Python ne trouve pas automatiquement `src/` depuis `scripts/`
- `sys.path.insert(0, str(src_dir))` ajoute `src/` au chemin de recherche

---

## ‚ö° **Flux d'ex√©cution d√©taill√©**

### **Sc√©nario complet : Analyse d'une image**

```bash
python scripts/ocr_detect.py --gpu test_images/books1.jpg
```

#### **Phase 1 : Initialisation (ocr_detect.py)**

```python
# 1. Parsing arguments
args = parser.parse_args()
# R√©sultat : image_path="test_images/books1.jpg", gpu=True, tesseract=False

# 2. Validation fichier
if not os.path.exists("test_images/books1.jpg"):
    print("‚ùå Image introuvable")
    sys.exit(1)

# 3. Configuration imports
script_dir = Path(__file__).parent      # scripts/
src_dir = script_dir.parent / "src"     # src/
sys.path.insert(0, str(src_dir))        # PYTHONPATH += src/

# 4. Import classe
from ocr_processor import BookOCR

# 5. Cr√©ation instance
processor = BookOCR(['en'], 0.2, use_gpu=True, use_tesseract=False)
# ‚Üì Appelle BookOCR.__init__()
```

#### **Phase 2 : Initialisation BookOCR**

```python
# BookOCR.__init__()
def __init__(self, languages, confidence_threshold, use_gpu=False, use_tesseract=False):
    self.use_tesseract = False
    self.confidence_threshold = 0.2
    
    # Initialisation EasyOCR avec GPU
    self.reader = easyocr.Reader(['en'], gpu=True)
    print("üîç OCR initialis√© - EasyOCR, Langues: ['en'], Seuil: 0.2, Device: GPU")
```

#### **Phase 3 : Chargement de l'image**

```python
# ocr_detect.py
pil_image = Image.open("test_images/books1.jpg")
# R√©sultat : Objet PIL.Image avec l'image charg√©e
```

#### **Phase 4 : Analyse OCR (get_text_and_confidence)**

```python
# ocr_detect.py
text, confidence = processor.get_text_and_confidence(pil_image, preprocess=False)

# ‚Üì D√©tail de l'appel
def get_text_and_confidence(self, pil_image, preprocess=False):
    # Conversion PIL ‚Üí NumPy ‚Üí BGR
    image_array = np.array(pil_image)
    bgr_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)
    
    # PAS de pr√©traitement (preprocess=False)
    
    # D√©tection EasyOCR
    results = self.reader.readtext(bgr_image, rotation_info=[0, 90, 180, 270])
    
    # Filtrage
    filtered_results = [
        r for r in results
        if r[2] >= 0.2 and len(r[1].strip()) >= 2
    ]
    
    # Agr√©gation
    texts = [r[1] for r in filtered_results]
    confidences = [r[2] for r in filtered_results]
    
    full_text = ' '.join(texts)
    avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
    
    return full_text, avg_confidence
```

#### **Phase 5 : Extraction des bo√Ætes (get_boxes)**

```python
# ocr_detect.py
boxes = processor.get_boxes(pil_image, preprocess=False)

# ‚Üì D√©tail de l'appel
def get_boxes(self, pil_image, preprocess=False, vertical_only=False):
    # M√™me d√©tection OCR que ci-dessus
    results = self.reader.readtext(bgr_image, rotation_info=[0, 90, 180, 270])
    
    boxes = []
    for bbox, text, confidence in results:
        if confidence >= 0.2 and len(text.strip()) >= 2:
            # Calcul dimensions
            x = min([p[0] for p in bbox])
            y = min([p[1] for p in bbox])
            width = max([p[0] for p in bbox]) - x
            height = max([p[1] for p in bbox]) - y
            font_size = self._calculate_font_size(bbox)
            
            # D√©tection verticale
            is_vertical = self._is_vertical_text(bbox)
            
            boxes.append({
                "text": text, "x": x, "y": y, "width": width, "height": height,
                "font_size": font_size, "is_vertical": is_vertical
            })
    
    return boxes
```

#### **Phase 6 : Regroupement par livres (get_books)**

```python
# ocr_detect.py
books = processor.get_books(pil_image, preprocess=False)

# ‚Üì D√©tail de l'appel
def get_books(self, pil_image, preprocess=True):
    # 1. Obtenir toutes les bo√Ætes
    boxes = self.get_boxes(pil_image, preprocess=preprocess, vertical_only=False)
    
    # 2. Regrouper par livres
    books = self.group_by_books(boxes)
    
    return books

# ‚Üì group_by_books() en d√©tail
def group_by_books(self, boxes, vertical_threshold=50):
    # 1. Filtrer vertical + grandes polices
    vertical_boxes = [b for b in boxes if b.get('is_vertical', False)]
    font_sizes = [b['font_size'] for b in vertical_boxes]
    median_font_size = sorted(font_sizes)[len(font_sizes) // 2]
    large_text_boxes = [b for b in vertical_boxes if b['font_size'] >= median_font_size * 0.8]
    
    # 2. Trier par position X
    sorted_boxes = sorted(large_text_boxes, key=lambda b: b['x'])
    
    # 3. Regrouper spatialement
    books = []
    current_book = [sorted_boxes[0]]
    current_x = sorted_boxes[0]['x']
    
    for box in sorted_boxes[1:]:
        if abs(box['x'] - current_x) <= 50:  # Seuil de 50px
            current_book.append(box)
        else:
            books.append(current_book)
            current_book = [box]
            current_x = box['x']
    
    if current_book:
        books.append(current_book)
    
    # 4. Extraire titres
    formatted_books = []
    for book_texts in books:
        title = self._extract_book_title(book_texts)
        formatted_books.append({
            'title': title,
            'x': book_texts[0]['x'],
            'all_texts': [b['text'] for b in book_texts],
            'text_count': len(book_texts)
        })
    
    return formatted_books
```

#### **Phase 7 : Affichage des r√©sultats**

```python
# ocr_detect.py
print(f"\nüìä R√©sultats:")
print(f"   Textes d√©tect√©s: {len(boxes)}")
print(f"   Livres d√©tect√©s: {len(books)}")
print(f"   Confiance: {confidence:.2f}")
print(f"   Texte: {text[:80]}{'...' if len(text) > 80 else ''}")

if books:
    print(f"\nüìö Livres d√©tect√©s ({len(books)}):")
    for i, book in enumerate(books, 1):
        print(f"   {i:2d}. {book['title']}")
        if book['text_count'] > 1:
            other_texts = ', '.join(book['all_texts'][:3])
            print(f"       ‚îî‚îÄ (+{book['text_count']-1} textes: {other_texts})")

print("\n‚úÖ Analyse termin√©e!")
```

### **Temps d'ex√©cution approximatif**

- **Initialisation EasyOCR** : 5-10 secondes (chargement mod√®le)
- **Chargement image** : < 1 seconde
- **D√©tection OCR** : 2-5 secondes (d√©pend de la taille image/GPU)
- **Regroupement** : < 1 seconde
- **Affichage** : < 1 seconde

**Total** : 8-17 secondes pour une premi√®re analyse

---

## üîÑ **R√©sum√© des interactions**

### **Hi√©rarchie des appels**
```
Utilisateur
    ‚Üì
ocr_detect.py::main()
    ‚Üì (import + instanciation)
BookOCR.__init__()
    ‚Üì (utilisation)
BookOCR.get_books()
    ‚îú‚îÄ‚îÄ BookOCR.get_boxes()
    ‚îÇ   ‚îú‚îÄ‚îÄ BookOCR._is_vertical_text()
    ‚îÇ   ‚îú‚îÄ‚îÄ BookOCR._calculate_font_size()
    ‚îÇ   ‚îî‚îÄ‚îÄ BookOCR.reader.readtext() [EasyOCR]
    ‚îî‚îÄ‚îÄ BookOCR.group_by_books()
        ‚îî‚îÄ‚îÄ BookOCR._extract_book_title()
```

### **Flux de donn√©es**
```
Arguments utilisateur ‚Üí Parsing ‚Üí Configuration ‚Üí Instanciation BookOCR
                                                                    ‚Üì
Image PIL ‚Üí get_books() ‚Üí get_boxes() ‚Üí OCR Engine ‚Üí Boxes filtr√©es
                                                                 ‚Üì
Boxes filtr√©es ‚Üí group_by_books() ‚Üí Regroupement spatial ‚Üí Livres
                                                                 ‚Üì
Livres ‚Üí Affichage format√© ‚Üí Utilisateur
```

### **Points de d√©cision**
- **Moteur OCR** : `use_tesseract` (Tesseract vs EasyOCR)
- **Acc√©l√©ration** : `use_gpu` (GPU vs CPU)
- **Pr√©traitement** : Param√®tre `preprocess` dans certaines m√©thodes
- **Filtrage vertical** : Param√®tre `vertical_only` dans `get_boxes()`

Cette architecture modulaire permet de **tester chaque composant ind√©pendamment** et de **r√©utiliser** la logique OCR dans diff√©rents contextes (interface web, API, etc.).

## üéØ **Comment utiliser le syst√®me**

Le syst√®me OCR modulaire de ShelfReader P1 offre **trois modes d'utilisation** :

### **Mode 1 : Script unifi√© (Recommand√©)**
```bash
cd p1-MVP-Desktop

# EasyOCR (par d√©faut, recommand√©)
python scripts/ocr_detect.py ../data/test_images/sample.jpg

# Avec GPU pour EasyOCR
python scripts/ocr_detect.py ../data/test_images/sample.jpg --engine easyocr --gpu

# Tesseract (rapide, CPU uniquement)
python scripts/ocr_detect.py ../data/test_images/sample.jpg --engine tesseract

# TrOCR (haute pr√©cision, GPU recommand√©)
python scripts/ocr_detect.py ../data/test_images/sample.jpg --engine trocr --gpu
```

### **Mode 2 : Modules individuels (D√©veloppement/Test)**
```bash
# Tester EasyOCR seul
python src/ocr_easyocr.py --image ../data/test_images/sample.jpg --gpu

# Tester Tesseract seul
python src/ocr_tesseract.py --image ../data/test_images/sample.jpg --psm 6

# Tester TrOCR seul
python src/ocr_trocr.py --image ../data/test_images/sample.jpg --gpu
```

### **Mode 3 : Int√©gration dans votre code**
```python
from src.ocr_easyocr import EasyOCRProcessor

# Initialisation
processor = EasyOCRProcessor(confidence_threshold=0.2, use_gpu=True)

# Utilisation
text, confidence = processor.detect_text("path/to/image.jpg")
print(f"Texte: {text}, Confiance: {confidence:.2f}")
```

### **Structure des fichiers actuelle**
```
p1-MVP-Desktop/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ocr_easyocr.py      # Module EasyOCR
‚îÇ   ‚îú‚îÄ‚îÄ ocr_tesseract.py    # Module Tesseract
‚îÇ   ‚îú‚îÄ‚îÄ ocr_trocr.py        # Module TrOCR
‚îÇ   ‚îú‚îÄ‚îÄ api_client.py       # Client Open Library
‚îÇ   ‚îú‚îÄ‚îÄ app.py              # Interface Streamlit (futur)
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ ocr_detect.py       # Script unifi√©
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ README.md           # Documentation principale
‚îÇ   ‚îú‚îÄ‚îÄ OCR_Code_Explanation.md  # Guide technique
‚îÇ   ‚îî‚îÄ‚îÄ Dependencies.md     # D√©pendances
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îî‚îÄ‚îÄ requirements.txt        # D√©pendances Python
```

---

## üéØ **Points cl√©s pour r√©ussir**

### 1. **Comprendre les d√©fis**
- Texte vertical sur tranches de livres
- Contraste et qualit√© variables
- Petits caract√®res difficiles √† d√©tecter

### 2. **Choisir le bon moteur OCR**
- **EasyOCR** : Plus pr√©cis, supporte les rotations, GPU acc√©l√©r√©
- **Tesseract** : Plus rapide, configurations PSM avanc√©es, CPU uniquement
- **TrOCR** : Haute pr√©cision, mod√®le transformer, GPU recommand√©

### 3. **Architecture modulaire**
- **S√©paration des responsabilit√©s** : Chaque moteur dans son propre module
- **Interface commune** : M√©thodes `detect_text()` et `get_text_and_confidence()`
- **CLI int√©gr√©** : Chaque module utilisable ind√©pendamment
- **Testabilit√©** : Tests unitaires par moteur OCR

### 4. **Optimisation des performances**
- **GPU** : EasyOCR et TrOCR supportent l'acc√©l√©ration GPU
- **CPU** : Tesseract pour les environnements sans GPU
- **Pr√©traitement** : Am√©liore significativement la pr√©cision
- **Seuil de confiance** : Ajuster selon la qualit√© des images

### 5. **Gestion des erreurs**
- Validation des fichiers d'entr√©e
- Gestion des imports manquants
- Messages d'erreur informatifs
- Robustesse individuelle des modules

---

*Ce document explique l'architecture modulaire OCR de ShelfReader P1. Chaque module peut √™tre utilis√© ind√©pendamment ou via le script unifi√© selon vos besoins.*</content>
<parameter name="filePath">/home/delart/Documents/dev/python/Shelfreader/p1-MVP-Desktop/docs/OCR_Code_Explanation.md