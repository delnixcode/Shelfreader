# ============================================
# ShelfReader - OCR Processor (Phase 1 - MVP Desktop)
# ============================================
"""
Module de traitement OCR pour la d√©tection de titres de livres.

Ce module utilise EasyOCR pour d√©tecter automatiquement les textes
sur les images de biblioth√®ques et extraire les titres de livres.

Fonctionnalit√©s principales:
- D√©tection OCR multi-langues (actuellement anglais)
- Pr√©traitement d'image optionnel (d√©sactiv√© pour meilleurs r√©sultats)
- Filtrage par seuil de confiance
- Extraction des coordonn√©es des textes d√©tect√©s

Auteur: ShelfReader Team
Date: 2025
"""

# ============================================
# IMPORTS ET D√âPENDANCES
# ============================================

import easyocr          # Biblioth√®que OCR principale
import cv2              # Traitement d'images OpenCV
import numpy as np      # Calculs num√©riques
from PIL import Image    # Manipulation d'images PIL/Pillow

# ============================================
# CLASSE PRINCIPALE - BookOCR
# ============================================

class BookOCR:
    """
    Classe principale pour le traitement OCR des images de livres.

    Cette classe encapsule toute la logique de d√©tection de texte
    sur les images de biblioth√®ques, avec support pour le pr√©traitement
    et le filtrage des r√©sultats.

    Attributs:
        reader (easyocr.Reader): Instance du lecteur OCR
        confidence_threshold (float): Seuil de confiance (0.0-1.0)
    """

    def __init__(self, languages, confidence_threshold):
        """
        Initialise le processeur OCR.

        Args:
            languages (list): Liste des langues √† d√©tecter (ex: ['en', 'fr'])
            confidence_threshold (float): Seuil minimum de confiance (0.0-1.0)
                                         Les textes avec une confiance inf√©rieure
                                         seront filtr√©s
        """
        # Cr√©er l'instance EasyOCR
        # gpu=False pour utiliser le CPU (plus lent mais compatible partout)
        self.reader = easyocr.Reader(languages, gpu=False)

        # Stocker le seuil de confiance pour le filtrage
        self.confidence_threshold = confidence_threshold

        print(f"üîç OCR initialis√© - Langues: {languages}, Seuil: {confidence_threshold}")

    def preprocess_image(self, image):
        """
        Applique un pr√©traitement √† l'image pour am√©liorer la d√©tection OCR.

        NOTE: Cette m√©thode est actuellement conserv√©e mais D√âSACTIV√âE
        par d√©faut car elle d√©gradait la qualit√© de d√©tection sur les
        images de biblioth√®ques naturelles.

        Args:
            image (numpy.ndarray): Image OpenCV (format BGR)

        Returns:
            numpy.ndarray: Image pr√©trait√©e en niveaux de gris
        """
        # Conversion en niveaux de gris
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # √âgalisation d'histogramme pour am√©liorer le contraste
        # (utile pour les textes peu contrast√©s)
        equalized = cv2.equalizeHist(gray)

        # R√©duction du bruit avec un flou gaussien l√©ger
        blurred = cv2.GaussianBlur(equalized, (3, 3), 0)

        # Am√©lioration du contraste avec CLAHE (Contrast Limited Adaptive Histogram Equalization)
        # clipLimit=4.0 : limite le contraste pour √©viter les artefacts
        # tileGridSize=(8,8) : taille des tuiles pour l'adaptation locale
        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8,8))
        enhanced = clahe.apply(blurred)

        # Augmentation de la nettet√© avec un filtre de convolution
        # Noyau de nettet√© : accentue les contours
        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
        sharpened = cv2.filter2D(enhanced, -1, kernel)

        # Redimensionnement si l'image est petite (< 1000px de hauteur)
        # Utile pour am√©liorer la d√©tection de petits textes
        height, width = sharpened.shape
        if height < 1000:
            scale_factor = 1000 / height
            new_width = int(width * scale_factor)
            sharpened = cv2.resize(sharpened, (new_width, 1000), interpolation=cv2.INTER_CUBIC)

        return sharpened

    # ============================================
    # M√âTHODES PRINCIPALES - EXTRACTION DE TEXTE
    # ============================================

    def get_text_and_confidence(self, pil_image, preprocess=True):
        """
        Extrait le texte d'une image et retourne la confiance moyenne.

        Cette m√©thode est le c≈ìur du syst√®me OCR. Elle prend une image PIL,
        applique optionnellement un pr√©traitement, d√©tecte le texte avec
        EasyOCR, filtre les r√©sultats et retourne le texte combin√© avec
        la confiance moyenne.

        Args:
            pil_image (PIL.Image): Image PIL (format RGB)
            preprocess (bool): Si True, applique le pr√©traitement d'image
                              (d√©sactiv√© par d√©faut pour meilleurs r√©sultats)

        Returns:
            tuple: (texte_combine, confiance_moyenne)
                   - texte_combine (str): Tous les textes d√©tect√©s concat√©n√©s
                   - confiance_moyenne (float): Moyenne des confiances (0.0-1.0)
        """
        # Conversion PIL ‚Üí NumPy array
        # PIL utilise le format RGB, OpenCV utilise BGR
        image_array = np.array(pil_image)

        # Conversion RGB ‚Üí BGR pour OpenCV
        # OpenCV attend le format BGR par d√©faut
        bgr_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)

        # Application du pr√©traitement si demand√©
        if preprocess:
            image = self.preprocess_image(bgr_image)
        else:
            # Utilisation directe de l'image originale (recommand√©)
            image = bgr_image

        # === D√âTECTION OCR AVEC EASYOCR ===
        # rotation_info : Liste des angles de rotation √† tester
        # [0, 90, 180, 270] = texte horizontal et vertical
        results = self.reader.readtext(image, rotation_info=[0, 90, 180, 270])

        # === FILTRAGE DES R√âSULTATS ===
        # Chaque r√©sultat EasyOCR est un tuple: (bounding_box, text, confidence)
        # On filtre par:
        # 1. Seuil de confiance minimum
        # 2. Longueur minimale du texte (√©vite les faux positifs)
        filtered_results = [
            r for r in results
            if r[2] >= self.confidence_threshold and len(r[1].strip()) >= 2
        ]

        # Extraction de tous les textes d√©tect√©s (apr√®s filtrage)
        texts = [r[1] for r in filtered_results]

        # Concat√©nation de tous les textes en une seule cha√Æne
        # S√©par√©s par des espaces pour la lisibilit√©
        full_text = ' '.join(texts)

        # Calcul de la confiance moyenne
        if filtered_results:
            # Somme des confiances divis√©e par le nombre de r√©sultats
            avg_confidence = sum(r[2] for r in filtered_results) / len(filtered_results)
        else:
            # Aucun r√©sultat d√©tect√©
            avg_confidence = 0.0

        # Retour du texte combin√© et de la confiance moyenne
        return (full_text, avg_confidence)

    def get_boxes(self, pil_image, preprocess=True):
        """
        Extrait les coordonn√©es (bounding boxes) des textes d√©tect√©s.

        Cette m√©thode retourne une liste d√©taill√©e de tous les textes d√©tect√©s
        avec leurs positions dans l'image. Utile pour visualiser ou traiter
        individuellement chaque texte trouv√©.

        Args:
            pil_image (PIL.Image): Image PIL (format RGB)
            preprocess (bool): Si True, applique le pr√©traitement d'image

        Returns:
            list: Liste de dictionnaires avec les cl√©s:
                  - 'text': Le texte d√©tect√© (str)
                  - 'x': Position X du coin sup√©rieur gauche (float)
                  - 'y': Position Y du coin sup√©rieur gauche (float)
                  - 'width': Largeur de la bo√Æte (float)
                  - 'height': Hauteur de la bo√Æte (float)
        """
        # Conversion PIL ‚Üí NumPy array (m√™me processus que get_text_and_confidence)
        image_array = np.array(pil_image)
        bgr_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)

        # Application du pr√©traitement si demand√©
        if preprocess:
            image = self.preprocess_image(bgr_image)
        else:
            image = bgr_image

        # D√©tection OCR avec EasyOCR (m√™mes param√®tres)
        results = self.reader.readtext(image, rotation_info=[0, 90, 180, 270])

        # === EXTRACTION DES COORDONN√âES ===
        boxes = []
        for r in results:
            text = r[1]          # Le texte d√©tect√©
            confidence = r[2]    # La confiance (0.0-1.0)
            bbox = r[0]          # Liste des 4 coins de la bo√Æte: [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]

            # Appliquer les m√™mes filtres que dans get_text_and_confidence
            if confidence >= self.confidence_threshold and len(text.strip()) >= 2:
                # Calcul des coordonn√©es de la bo√Æte englobante
                # x = coordonn√©e X minimale (coin gauche)
                # y = coordonn√©e Y minimale (coin sup√©rieur)
                # width = largeur = Xmax - Xmin
                # height = hauteur = Ymax - Ymin
                x = min([p[0] for p in bbox])
                y = min([p[1] for p in bbox])
                width = max([p[0] for p in bbox]) - x
                height = max([p[1] for p in bbox]) - y

                # Ajouter √† la liste des r√©sultats
                boxes.append({
                    "text": text,
                    "x": x,
                    "y": y,
                    "width": width,
                    "height": height
                })

        # Retourner la liste compl√®te des bo√Ætes d√©tect√©es
        return boxes


# ============================================
# SECTION PRINCIPALE - TESTS ET D√âMONSTRATION
# ============================================

if __name__ == "__main__":
    """
    Point d'entr√©e pour les tests en ligne de commande.

    Permet de tester rapidement le processeur OCR sur une image
    en ex√©cutant directement le fichier Python.

    Usage: python ocr_processor.py <chemin_image>
    """
    import sys
    import os

    # V√©rification des arguments
    if len(sys.argv) != 2:
        print("Usage: python ocr_processor.py <image_path>")
        print("Example: python ocr_processor.py ../data/test_images/books.jpg")
        sys.exit(1)

    image_path = sys.argv[1]

    # V√©rification que l'image existe
    if not os.path.exists(image_path):
        print(f"Image not found: {image_path}")
        sys.exit(1)

    # === INITIALISATION ===
    # Cr√©er une instance de BookOCR
    # - Langue: Anglais ['en']
    # - Seuil de confiance: 0.2 (permissif pour d√©tecter plus de texte)
    processor = BookOCR(['en'], 0.2)

    # === CHARGEMENT DE L'IMAGE ===
    pil_image = Image.open(image_path)

    # === TRAITEMENT OCR ===
    print(f"üîç Processing image: {image_path}")

    # D√©sactiver le pr√©processing pour de meilleurs r√©sultats
    text, confidence = processor.get_text_and_confidence(pil_image, preprocess=False)
    boxes = processor.get_boxes(pil_image, preprocess=False)

    # === AFFICHAGE DES R√âSULTATS ===
    print("\nüìä === OCR Results ===")
    print(f"üìù Text: {text}")
    print(f"üéØ Confidence: {confidence:.3f}")
    print(f"üìö Number of text boxes: {len(boxes)}")

    # Afficher le d√©tail de chaque bo√Æte d√©tect√©e
    if boxes:
        print("\nüìç All detected boxes:")
        for i, box in enumerate(boxes):
            print(f"  Box {i+1}: {box}")

    print("\n‚úÖ Processing complete!")

